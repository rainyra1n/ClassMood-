{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96412c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from scipy.spatial.transform import Rotation as R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a54679f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeadPose:\n",
    "    def __init__(self):\n",
    "        self.bb_detection = YOLO(r'C:/Users/Stepan/Documents/ClassMood/yunet_headpose/yolov8n-face-lindevs.pt')\n",
    "        self.face_mesh = mp.solutions.face_mesh.FaceMesh(\n",
    "            static_image_mode=True,\n",
    "            max_num_faces=1,\n",
    "            refine_landmarks=True,\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5\n",
    "        )\n",
    "\n",
    "    def calibrate_matrix(self, chb_size, images=None, video=None):\n",
    "        chessboard_size = (chb_size[0] - 1, chb_size[1] - 1)\n",
    "        objp = np.zeros((chessboard_size[0] * chessboard_size[1], 3), dtype=np.float32)\n",
    "        objp[:, :2] = np.mgrid[0:chessboard_size[0], 0:chessboard_size[1]].T.reshape(-1, 2)\n",
    "        objpoints, imgpoints = [], []\n",
    "        calibration_data = []\n",
    "\n",
    "        if images:\n",
    "            if len(images) < 10:\n",
    "                raise Exception('Пожалуйста, введите не менее 10 фотографий')\n",
    "            calibration_data = images\n",
    "            calibration_mode = 'img'\n",
    "        else:\n",
    "            cap = cv2.VideoCapture(video)\n",
    "            if (cap.get(cv2.CAP_PROP_FRAME_COUNT) / cap.get(cv2.CAP_PROP_FPS)) < 2:\n",
    "                raise Exception('Пожалуйста, введите видео длинной более двух секунд')\n",
    "            \n",
    "            frame_skip = cap.get(cv2.CAP_PROP_FRAME_COUNT) // 5\n",
    "            frame_count = 0\n",
    "\n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                if frame_count % frame_skip == 0:\n",
    "                    calibration_data.append(frame)\n",
    "                frame_count += 1\n",
    "            calibration_mode = 'vid'\n",
    "\n",
    "        for path in calibration_data:\n",
    "            if calibration_mode == 'img':\n",
    "                img = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2GRAY)\n",
    "            else:\n",
    "                img = cv2.cvtColor(path, cv2.COLOR_BGR2GRAY)\n",
    "            found, corners = cv2.findChessboardCorners(img, chessboard_size, None)\n",
    "\n",
    "            if found:\n",
    "                objpoints.append(objp)\n",
    "\n",
    "                corners_refined = cv2.cornerSubPix(img, corners, (11, 11), (-1, -1), (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001))\n",
    "                imgpoints.append(corners_refined)\n",
    "        h, w = img.shape[:2]\n",
    "\n",
    "        ret, camera_matrix, self.dist_coeffs, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, (w, h), None, None)\n",
    "        self.matrix = cv2.getOptimalNewCameraMatrix(camera_matrix, self.dist_coeffs, (w, h), 1, (w, h))[0]\n",
    "\n",
    "    def frame_headpose(self, path):\n",
    "        bb_results = self.bb_detection(path, conf=0.4)\n",
    "        try:\n",
    "            image = cv2.imread(path)\n",
    "        except:\n",
    "            image = path\n",
    "\n",
    "        if not bb_results:\n",
    "            return None\n",
    "        \n",
    "        h, w = image.shape[:2]\n",
    "        boxes = bb_results[0].boxes.xyxy.numpy()\n",
    "        head_rotations = dict()\n",
    "        point_names = ('nose', 'chin', 'left eye inner', 'right eye inner', 'mouth left', 'mouth right', 'right eye outer', 'left eye outer')\n",
    "\n",
    "        for face_id, coords in enumerate(boxes):\n",
    "            face_roi = image[int(coords[1]):int(coords[3]), int(coords[0]):int(coords[2])]\n",
    "            mesh_results = self.face_mesh.process(cv2.cvtColor(face_roi, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "            roi_h, roi_w = face_roi.shape[:2]\n",
    "            landmarks_3d = dict(zip(point_names, [(mesh_results.multi_face_landmarks[-1].landmark[i].x, mesh_results.multi_face_landmarks[-1].landmark[i].y, mesh_results.multi_face_landmarks[-1].landmark[i].z) for i in (1, 152, 130, 359, 78, 308, 362, 133)]))\n",
    "\n",
    "            roll = math.degrees(math.atan2(landmarks_3d['right eye outer'][0] - landmarks_3d['left eye outer'][0], landmarks_3d['right eye outer'][1] - landmarks_3d['left eye outer'][1]))\n",
    "            yaw_approx = ((((landmarks_3d['left eye inner'][0] - landmarks_3d['nose'][0]) ** 2 + (landmarks_3d['left eye inner'][1] - landmarks_3d['nose'][1]) ** 2) ** 0.5) - (((landmarks_3d['right eye inner'][0] - landmarks_3d['nose'][0]) ** 2 + (landmarks_3d['right eye inner'][1] - landmarks_3d['nose'][1]) ** 2) ** 0.5)) / roi_w * 100000 \n",
    "            pitch_approx = (landmarks_3d['nose'][2] + landmarks_3d['chin'][2]) * -100\n",
    "\n",
    "            head_rotations[face_id] = (yaw_approx / (w / max((coords[0] + coords[2]), 0.1 ** 6)), pitch_approx, roll)\n",
    "        \n",
    "        return head_rotations\n",
    "    \n",
    "    def video_headpose(self, path):\n",
    "        cap = cv2.VideoCapture(path)\n",
    "        frame_count = 0\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        main_df = dict()\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            if frame_count % 5 == 0:\n",
    "                temp = self.frame_headpose(frame)\n",
    "                main_df[round(frame_count / fps, 3)] = {i: {'yaw': round(temp[i][0], 3), 'pitch': round(temp[i][1], 3), 'roll': round(temp[i][2], 3)} for i in temp.keys()}\n",
    "\n",
    "            frame_count += 1\n",
    "        \n",
    "        return main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c962489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "headpose = HeadPose()\n",
    "headpose.calibrate_matrix((8, 8), images=[f'c:/Users/Stepan/Documents/ClassMood/yunet_headpose/images/calib_images/{i}.jpg' for i in range(12, 22)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e9f52869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Stepan\\Documents\\ClassMood\\yunet_headpose\\images\\test_images\\shift (1).jpg: 640x480 1 face, 35.5ms\n",
      "Speed: 3.2ms preprocess, 35.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 C:\\Users\\Stepan\\Documents\\ClassMood\\yunet_headpose\\images\\test_images\\shift (2).jpg: 640x480 1 face, 32.0ms\n",
      "Speed: 2.9ms preprocess, 32.0ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 C:\\Users\\Stepan\\Documents\\ClassMood\\yunet_headpose\\images\\test_images\\shift (3).jpg: 640x480 1 face, 31.8ms\n",
      "Speed: 2.4ms preprocess, 31.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 C:\\Users\\Stepan\\Documents\\ClassMood\\yunet_headpose\\images\\test_images\\shift (4).jpg: 640x480 1 face, 31.1ms\n",
      "Speed: 2.2ms preprocess, 31.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 C:\\Users\\Stepan\\Documents\\ClassMood\\yunet_headpose\\images\\test_images\\shift (5).jpg: 640x480 1 face, 30.6ms\n",
      "Speed: 3.0ms preprocess, 30.6ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 C:\\Users\\Stepan\\Documents\\ClassMood\\yunet_headpose\\images\\test_images\\shift (6).jpg: 640x480 1 face, 30.4ms\n",
      "Speed: 2.3ms preprocess, 30.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 C:\\Users\\Stepan\\Documents\\ClassMood\\yunet_headpose\\images\\test_images\\shift (7).jpg: 640x480 1 face, 27.4ms\n",
      "Speed: 2.2ms preprocess, 27.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "[{0: (np.float32(-7.2366843), 8.154100179672241, 87.70463062388164)}, {0: (np.float32(-8.751207), 9.959454834461212, 86.90119321761307)}, {0: (np.float32(-13.21737), 7.563021779060364, 87.16001771425971)}, {0: (np.float32(-10.927129), 9.98910367488861, 87.42962357506015)}, {0: (np.float32(-12.096377), 8.03658813238144, 86.59921103835033)}, {0: (np.float32(-11.241756), 6.175936758518219, 86.04946410882414)}, {0: (np.float32(-8.539178), 12.02995777130127, 87.38257733925685)}]\n"
     ]
    }
   ],
   "source": [
    "print([headpose.frame_headpose(path=f'C:/Users/Stepan/Documents/ClassMood/yunet_headpose/images/test_images/shift ({i}).jpg') for i in range(1, 8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "44fc3734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Stepan\\Documents\\ClassMood\\yunet_headpose\\images\\test_images\\test (2).jpg: 640x480 2 faces, 29.0ms\n",
      "Speed: 1.8ms preprocess, 29.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "inner eye to mouth, left and right: 0.4470449854166757 0.384401154430455\n"
     ]
    }
   ],
   "source": [
    "mesh_results = headpose.frame_headpose(path='C:/Users/Stepan/Documents/ClassMood/yunet_headpose/images/test_images/test (2).jpg')\n",
    "landmarks_3d = dict(zip(('nose', 'chin', 'left eye inner', 'right eye inner', 'mouth left', 'mouth right', 'right eye outer', 'left eye outer'), [(mesh_results.multi_face_landmarks[0].landmark[i].x, mesh_results.multi_face_landmarks[0].landmark[i].y, mesh_results.multi_face_landmarks[0].landmark[i].z) for i in (1, 152, 130, 359, 78, 308, 362, 133)]))\n",
    "roll = math.degrees(math.atan2(landmarks_3d['right eye outer'][0] - landmarks_3d['left eye outer'][0], landmarks_3d['right eye outer'][1] - landmarks_3d['left eye outer'][1]))\n",
    "yaw_approx = (landmarks_3d['right eye inner'][0] - landmarks_3d['left eye inner'][0] - landmarks_3d['right eye outer'][2] + landmarks_3d['left eye outer'][2]) * 50\n",
    "pitch_approx = (landmarks_3d['nose'][2] + landmarks_3d['chin'][2]) * -100\n",
    "\n",
    "print('inner eye to mouth, left and right:', ((landmarks_3d['left eye inner'][0] - landmarks_3d['mouth left'][0]) ** 2 + (landmarks_3d['left eye inner'][1] - landmarks_3d['mouth left'][1]) ** 2) ** 0.5, ((landmarks_3d['right eye inner'][0] - landmarks_3d['mouth right'][0]) ** 2 + (landmarks_3d['right eye inner'][1] - landmarks_3d['mouth right'][1]) ** 2) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "987dc69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "headpose = HeadPose()\n",
    "headpose.calibrate_matrix((8, 8), video='C:/Users/Stepan/Documents/ClassMood/yunet_headpose/videos/calib/vid1.MOV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfba7122",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = headpose.frame_headpose(path=r'C:/Users/Stepan/Documents/ClassMood/yunet_headpose/images/full_face_images/1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf4221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "90caee65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 1 face, 34.3ms\n",
      "Speed: 2.1ms preprocess, 34.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "286\n",
      "\n",
      "0: 640x384 1 face, 29.9ms\n",
      "Speed: 1.6ms preprocess, 29.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "285\n",
      "\n",
      "0: 640x384 1 face, 26.5ms\n",
      "Speed: 1.4ms preprocess, 26.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "280\n",
      "\n",
      "0: 640x384 1 face, 26.7ms\n",
      "Speed: 1.2ms preprocess, 26.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "284\n",
      "\n",
      "0: 640x384 1 face, 26.3ms\n",
      "Speed: 1.1ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "286\n",
      "\n",
      "0: 640x384 1 face, 27.9ms\n",
      "Speed: 1.5ms preprocess, 27.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "284\n",
      "\n",
      "0: 640x384 1 face, 24.9ms\n",
      "Speed: 1.1ms preprocess, 24.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "283\n",
      "\n",
      "0: 640x384 1 face, 34.4ms\n",
      "Speed: 1.9ms preprocess, 34.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "284\n",
      "\n",
      "0: 640x384 1 face, 23.1ms\n",
      "Speed: 1.6ms preprocess, 23.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "279\n",
      "\n",
      "0: 640x384 1 face, 23.3ms\n",
      "Speed: 1.1ms preprocess, 23.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "281\n",
      "\n",
      "0: 640x384 1 face, 24.4ms\n",
      "Speed: 1.3ms preprocess, 24.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "269\n",
      "\n",
      "0: 640x384 1 face, 24.4ms\n",
      "Speed: 1.2ms preprocess, 24.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "269\n",
      "\n",
      "0: 640x384 1 face, 29.0ms\n",
      "Speed: 1.2ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "274\n",
      "\n",
      "0: 640x384 1 face, 28.4ms\n",
      "Speed: 1.9ms preprocess, 28.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "268\n",
      "\n",
      "0: 640x384 1 face, 28.7ms\n",
      "Speed: 1.2ms preprocess, 28.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "271\n",
      "\n",
      "0: 640x384 1 face, 30.1ms\n",
      "Speed: 2.5ms preprocess, 30.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "275\n",
      "\n",
      "0: 640x384 1 face, 29.4ms\n",
      "Speed: 1.1ms preprocess, 29.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "274\n",
      "\n",
      "0: 640x384 1 face, 28.0ms\n",
      "Speed: 1.4ms preprocess, 28.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "272\n",
      "\n",
      "0: 640x384 1 face, 31.0ms\n",
      "Speed: 1.2ms preprocess, 31.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "274\n",
      "\n",
      "0: 640x384 1 face, 30.0ms\n",
      "Speed: 1.5ms preprocess, 30.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "278\n",
      "\n",
      "0: 640x384 1 face, 34.0ms\n",
      "Speed: 1.3ms preprocess, 34.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "282\n",
      "\n",
      "0: 640x384 1 face, 29.6ms\n",
      "Speed: 1.2ms preprocess, 29.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "283\n",
      "\n",
      "0: 640x384 1 face, 29.1ms\n",
      "Speed: 1.5ms preprocess, 29.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "295\n",
      "\n",
      "0: 640x384 1 face, 27.7ms\n",
      "Speed: 1.3ms preprocess, 27.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "283\n",
      "\n",
      "0: 640x384 1 face, 26.9ms\n",
      "Speed: 4.5ms preprocess, 26.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "279\n",
      "\n",
      "0: 640x384 1 face, 24.2ms\n",
      "Speed: 1.2ms preprocess, 24.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "266\n",
      "\n",
      "0: 640x384 1 face, 29.5ms\n",
      "Speed: 1.7ms preprocess, 29.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "272\n",
      "\n",
      "0: 640x384 1 face, 29.1ms\n",
      "Speed: 1.4ms preprocess, 29.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "275\n",
      "\n",
      "0: 640x384 1 face, 27.4ms\n",
      "Speed: 1.4ms preprocess, 27.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "275\n",
      "\n",
      "0: 640x384 1 face, 27.6ms\n",
      "Speed: 1.9ms preprocess, 27.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "274\n",
      "\n",
      "0: 640x384 1 face, 27.9ms\n",
      "Speed: 1.1ms preprocess, 27.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "273\n",
      "\n",
      "0: 640x384 1 face, 26.2ms\n",
      "Speed: 1.6ms preprocess, 26.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "282\n",
      "\n",
      "0: 640x384 1 face, 28.2ms\n",
      "Speed: 2.8ms preprocess, 28.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "290\n",
      "\n",
      "0: 640x384 1 face, 26.1ms\n",
      "Speed: 2.2ms preprocess, 26.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "275\n",
      "\n",
      "0: 640x384 1 face, 29.5ms\n",
      "Speed: 2.6ms preprocess, 29.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "278\n",
      "\n",
      "0: 640x384 1 face, 27.0ms\n",
      "Speed: 2.2ms preprocess, 27.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "278\n",
      "\n",
      "0: 640x384 1 face, 27.3ms\n",
      "Speed: 1.4ms preprocess, 27.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "275\n",
      "\n",
      "0: 640x384 1 face, 28.0ms\n",
      "Speed: 2.2ms preprocess, 28.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "280\n",
      "\n",
      "0: 640x384 1 face, 30.6ms\n",
      "Speed: 1.5ms preprocess, 30.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "280\n",
      "\n",
      "0: 640x384 1 face, 26.3ms\n",
      "Speed: 1.4ms preprocess, 26.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "283\n",
      "\n",
      "0: 640x384 1 face, 28.5ms\n",
      "Speed: 1.3ms preprocess, 28.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "286\n",
      "\n",
      "0: 640x384 1 face, 26.9ms\n",
      "Speed: 1.4ms preprocess, 26.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "290\n",
      "\n",
      "0: 640x384 1 face, 25.4ms\n",
      "Speed: 1.5ms preprocess, 25.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "288\n",
      "\n",
      "0: 640x384 1 face, 29.5ms\n",
      "Speed: 1.4ms preprocess, 29.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "292\n",
      "\n",
      "0: 640x384 1 face, 25.5ms\n",
      "Speed: 1.7ms preprocess, 25.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "290\n",
      "\n",
      "0: 640x384 1 face, 27.0ms\n",
      "Speed: 3.3ms preprocess, 27.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "291\n",
      "\n",
      "0: 640x384 1 face, 28.2ms\n",
      "Speed: 2.2ms preprocess, 28.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "286\n",
      "\n",
      "0: 640x384 1 face, 25.7ms\n",
      "Speed: 1.4ms preprocess, 25.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "287\n",
      "\n",
      "0: 640x384 1 face, 25.4ms\n",
      "Speed: 1.8ms preprocess, 25.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "282\n",
      "\n",
      "0: 640x384 1 face, 27.6ms\n",
      "Speed: 2.7ms preprocess, 27.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "284\n",
      "\n",
      "0: 640x384 1 face, 26.9ms\n",
      "Speed: 1.1ms preprocess, 26.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "285\n",
      "\n",
      "0: 640x384 1 face, 27.0ms\n",
      "Speed: 1.9ms preprocess, 27.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "283\n",
      "\n",
      "0: 640x384 1 face, 29.7ms\n",
      "Speed: 1.6ms preprocess, 29.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "290\n",
      "\n",
      "0: 640x384 1 face, 26.1ms\n",
      "Speed: 1.4ms preprocess, 26.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "284\n",
      "\n",
      "0: 640x384 1 face, 28.6ms\n",
      "Speed: 2.2ms preprocess, 28.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "275\n",
      "\n",
      "0: 640x384 1 face, 27.4ms\n",
      "Speed: 2.6ms preprocess, 27.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "260\n",
      "\n",
      "0: 640x384 1 face, 27.3ms\n",
      "Speed: 1.5ms preprocess, 27.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "252\n",
      "\n",
      "0: 640x384 1 face, 29.7ms\n",
      "Speed: 1.5ms preprocess, 29.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "251\n",
      "\n",
      "0: 640x384 1 face, 26.8ms\n",
      "Speed: 2.8ms preprocess, 26.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "256\n",
      "\n",
      "0: 640x384 1 face, 27.2ms\n",
      "Speed: 1.5ms preprocess, 27.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "256\n",
      "\n",
      "0: 640x384 1 face, 28.8ms\n",
      "Speed: 2.9ms preprocess, 28.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "265\n",
      "\n",
      "0: 640x384 1 face, 26.7ms\n",
      "Speed: 1.2ms preprocess, 26.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "274\n",
      "\n",
      "0: 640x384 1 face, 30.8ms\n",
      "Speed: 2.6ms preprocess, 30.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "276\n",
      "\n",
      "0: 640x384 1 face, 28.6ms\n",
      "Speed: 1.6ms preprocess, 28.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "279\n",
      "\n",
      "0: 640x384 1 face, 31.8ms\n",
      "Speed: 1.7ms preprocess, 31.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "284\n",
      "\n",
      "0: 640x384 1 face, 27.3ms\n",
      "Speed: 1.2ms preprocess, 27.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "293\n",
      "\n",
      "0: 640x384 1 face, 29.3ms\n",
      "Speed: 2.5ms preprocess, 29.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "292\n",
      "\n",
      "0: 640x384 1 face, 35.3ms\n",
      "Speed: 5.0ms preprocess, 35.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "294\n",
      "\n",
      "0: 640x384 1 face, 27.6ms\n",
      "Speed: 1.3ms preprocess, 27.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "304\n",
      "\n",
      "0: 640x384 1 face, 27.0ms\n",
      "Speed: 1.5ms preprocess, 27.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "331\n",
      "\n",
      "0: 640x384 1 face, 33.0ms\n",
      "Speed: 1.6ms preprocess, 33.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "343\n",
      "\n",
      "0: 640x384 1 face, 27.8ms\n",
      "Speed: 1.2ms preprocess, 27.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "353\n",
      "\n",
      "0: 640x384 1 face, 28.8ms\n",
      "Speed: 2.4ms preprocess, 28.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "366\n",
      "\n",
      "0: 640x384 1 face, 25.2ms\n",
      "Speed: 2.0ms preprocess, 25.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "369\n",
      "\n",
      "0: 640x384 1 face, 31.4ms\n",
      "Speed: 1.3ms preprocess, 31.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "361\n",
      "\n",
      "0: 640x384 1 face, 29.4ms\n",
      "Speed: 1.6ms preprocess, 29.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "343\n",
      "\n",
      "0: 640x384 1 face, 27.4ms\n",
      "Speed: 2.4ms preprocess, 27.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "325\n",
      "\n",
      "0: 640x384 1 face, 27.7ms\n",
      "Speed: 1.5ms preprocess, 27.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "314\n",
      "\n",
      "0: 640x384 1 face, 30.5ms\n",
      "Speed: 2.0ms preprocess, 30.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "305\n",
      "\n",
      "0: 640x384 1 face, 26.8ms\n",
      "Speed: 1.3ms preprocess, 26.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "302\n",
      "\n",
      "0: 640x384 1 face, 30.7ms\n",
      "Speed: 2.1ms preprocess, 30.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "291\n",
      "\n",
      "0: 640x384 1 face, 29.0ms\n",
      "Speed: 1.8ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "293\n",
      "\n",
      "0: 640x384 1 face, 26.5ms\n",
      "Speed: 1.5ms preprocess, 26.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "308\n",
      "\n",
      "0: 640x384 1 face, 27.2ms\n",
      "Speed: 1.4ms preprocess, 27.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "329\n",
      "\n",
      "0: 640x384 1 face, 27.0ms\n",
      "Speed: 1.6ms preprocess, 27.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "349\n",
      "\n",
      "0: 640x384 1 face, 29.1ms\n",
      "Speed: 1.5ms preprocess, 29.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "362\n",
      "\n",
      "0: 640x384 1 face, 28.6ms\n",
      "Speed: 1.3ms preprocess, 28.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "361\n",
      "\n",
      "0: 640x384 1 face, 26.3ms\n",
      "Speed: 1.1ms preprocess, 26.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "360\n",
      "\n",
      "0: 640x384 1 face, 24.7ms\n",
      "Speed: 1.3ms preprocess, 24.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "346\n",
      "\n",
      "0: 640x384 1 face, 25.5ms\n",
      "Speed: 1.5ms preprocess, 25.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "319\n",
      "\n",
      "0: 640x384 1 face, 28.7ms\n",
      "Speed: 1.4ms preprocess, 28.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "290\n",
      "\n",
      "0: 640x384 1 face, 27.9ms\n",
      "Speed: 1.4ms preprocess, 27.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "279\n",
      "\n",
      "0: 640x384 1 face, 28.7ms\n",
      "Speed: 1.7ms preprocess, 28.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "280\n",
      "\n",
      "0: 640x384 1 face, 30.4ms\n",
      "Speed: 1.3ms preprocess, 30.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "282\n"
     ]
    }
   ],
   "source": [
    "result1 = headpose.video_headpose(r'c:/Users/Stepan/Documents/ClassMood/yunet_headpose/videos/vid2.MOV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8a0f6a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: {0: {'yaw': -9.071, 'pitch': 3.763, 'roll': 88.509}},\n",
       " 0.167: {0: {'yaw': -11.485, 'pitch': 3.748, 'roll': 88.425}},\n",
       " 0.333: {0: {'yaw': -15.315, 'pitch': 3.092, 'roll': 88.528}},\n",
       " 0.5: {0: {'yaw': -6.745, 'pitch': 3.722, 'roll': 88.602}},\n",
       " 0.667: {0: {'yaw': -8.866, 'pitch': 4.698, 'roll': 87.901}},\n",
       " 0.833: {0: {'yaw': -5.991, 'pitch': 3.09, 'roll': 89.163}},\n",
       " 1.0: {0: {'yaw': 9.399, 'pitch': 3.932, 'roll': 89.35}},\n",
       " 1.167: {0: {'yaw': 24.382, 'pitch': 3.18, 'roll': 90.298}},\n",
       " 1.333: {0: {'yaw': 49.504, 'pitch': 4.322, 'roll': 90.684}},\n",
       " 1.5: {0: {'yaw': 79.847, 'pitch': 5.599, 'roll': 93.916}},\n",
       " 1.667: {0: {'yaw': 97.385, 'pitch': 5.456, 'roll': 91.834}},\n",
       " 1.833: {0: {'yaw': 123.303, 'pitch': 6.255, 'roll': 92.661}},\n",
       " 2.0: {0: {'yaw': 120.203, 'pitch': 5.475, 'roll': 92.981}},\n",
       " 2.167: {0: {'yaw': 131.051, 'pitch': 8.048, 'roll': 93.208}},\n",
       " 2.333: {0: {'yaw': 127.304, 'pitch': 6.342, 'roll': 93.761}},\n",
       " 2.5: {0: {'yaw': 119.683, 'pitch': 5.641, 'roll': 93.002}},\n",
       " 2.667: {0: {'yaw': 117.335, 'pitch': 5.694, 'roll': 92.302}},\n",
       " 2.833: {0: {'yaw': 127.231, 'pitch': 8.098, 'roll': 95.032}},\n",
       " 3.0: {0: {'yaw': 86.645, 'pitch': 8.58, 'roll': 91.858}},\n",
       " 3.167: {0: {'yaw': 65.853, 'pitch': 7.624, 'roll': 91.447}},\n",
       " 3.333: {0: {'yaw': 24.302, 'pitch': 5.119, 'roll': 89.421}},\n",
       " 3.5: {0: {'yaw': -21.679, 'pitch': 4.734, 'roll': 87.19}},\n",
       " 3.667: {0: {'yaw': -51.291, 'pitch': 3.152, 'roll': 85.009}},\n",
       " 3.833: {0: {'yaw': -80.974, 'pitch': 1.157, 'roll': 84.051}},\n",
       " 4.0: {0: {'yaw': -99.363, 'pitch': -0.119, 'roll': 83.151}},\n",
       " 4.167: {0: {'yaw': -124.86, 'pitch': 3.069, 'roll': 82.384}},\n",
       " 4.333: {0: {'yaw': -128.989, 'pitch': 4.052, 'roll': 82.503}},\n",
       " 4.5: {0: {'yaw': -123.885, 'pitch': 1.937, 'roll': 81.742}},\n",
       " 4.667: {0: {'yaw': -125.273, 'pitch': 1.797, 'roll': 81.883}},\n",
       " 4.833: {0: {'yaw': -125.585, 'pitch': 1.918, 'roll': 82.277}},\n",
       " 5.0: {0: {'yaw': -139.934, 'pitch': 5.204, 'roll': 83.997}},\n",
       " 5.167: {0: {'yaw': -93.875, 'pitch': 8.549, 'roll': 85.338}},\n",
       " 5.333: {0: {'yaw': -29.142, 'pitch': 6.484, 'roll': 87.468}},\n",
       " 5.5: {0: {'yaw': -6.366, 'pitch': 8.723, 'roll': 89.055}},\n",
       " 5.667: {0: {'yaw': -2.175, 'pitch': 8.98, 'roll': 88.622}},\n",
       " 5.833: {0: {'yaw': -5.167, 'pitch': 8.417, 'roll': 87.863}},\n",
       " 6.0: {0: {'yaw': -11.268, 'pitch': 5.318, 'roll': 87.454}},\n",
       " 6.167: {0: {'yaw': -15.476, 'pitch': -1.703, 'roll': 88.092}},\n",
       " 6.333: {0: {'yaw': -3.584, 'pitch': -9.333, 'roll': 87.41}},\n",
       " 6.5: {0: {'yaw': 6.393, 'pitch': -12.691, 'roll': 86.542}},\n",
       " 6.667: {0: {'yaw': 2.492, 'pitch': -21.101, 'roll': 86.197}},\n",
       " 6.833: {0: {'yaw': 0.394, 'pitch': -22.915, 'roll': 86.503}},\n",
       " 7.0: {0: {'yaw': -10.515, 'pitch': -26.563, 'roll': 87.528}},\n",
       " 7.167: {0: {'yaw': -3.413, 'pitch': -27.739, 'roll': 88.483}},\n",
       " 7.333: {0: {'yaw': -3.156, 'pitch': -26.991, 'roll': 87.12}},\n",
       " 7.5: {0: {'yaw': 0.406, 'pitch': -25.769, 'roll': 87.192}},\n",
       " 7.667: {0: {'yaw': 2.407, 'pitch': -25.322, 'roll': 87.076}},\n",
       " 7.833: {0: {'yaw': 2.045, 'pitch': -18.507, 'roll': 87.512}},\n",
       " 8.0: {0: {'yaw': -16.194, 'pitch': -6.633, 'roll': 89.175}},\n",
       " 8.167: {0: {'yaw': -22.378, 'pitch': 5.938, 'roll': 88.782}},\n",
       " 8.333: {0: {'yaw': -20.76, 'pitch': 11.855, 'roll': 89.384}},\n",
       " 8.5: {0: {'yaw': -15.395, 'pitch': 18.337, 'roll': 89.217}},\n",
       " 8.667: {0: {'yaw': -18.081, 'pitch': 29.57, 'roll': 88.668}},\n",
       " 8.833: {0: {'yaw': -16.037, 'pitch': 42.684, 'roll': 87.497}},\n",
       " 9.0: {0: {'yaw': -8.053, 'pitch': 50.13, 'roll': 88.64}},\n",
       " 9.167: {0: {'yaw': -10.627, 'pitch': 53.403, 'roll': 88.001}},\n",
       " 9.333: {0: {'yaw': -15.363, 'pitch': 54.163, 'roll': 87.774}},\n",
       " 9.5: {0: {'yaw': -12.31, 'pitch': 54.265, 'roll': 87.564}},\n",
       " 9.667: {0: {'yaw': -14.284, 'pitch': 55.875, 'roll': 88.054}},\n",
       " 9.833: {0: {'yaw': -11.326, 'pitch': 54.441, 'roll': 88.733}},\n",
       " 10.0: {0: {'yaw': -8.84, 'pitch': 50.949, 'roll': 88.867}},\n",
       " 10.167: {0: {'yaw': -10.772, 'pitch': 44.402, 'roll': 87.945}},\n",
       " 10.333: {0: {'yaw': -5.001, 'pitch': 30.092, 'roll': 88.962}},\n",
       " 10.5: {0: {'yaw': -1.693, 'pitch': 15.408, 'roll': 88.656}},\n",
       " 10.667: {0: {'yaw': -4.289, 'pitch': 4.279, 'roll': 88.288}},\n",
       " 10.833: {0: {'yaw': -4.955, 'pitch': -0.565, 'roll': 88.18}},\n",
       " 11.0: {0: {'yaw': -4.634, 'pitch': 1.675, 'roll': 88.648}},\n",
       " 11.167: {0: {'yaw': 0.072, 'pitch': 3.213, 'roll': 90.5}},\n",
       " 11.333: {0: {'yaw': -1.471, 'pitch': 5.774, 'roll': 94.059}},\n",
       " 11.5: {0: {'yaw': 3.377, 'pitch': 8.443, 'roll': 100.36}},\n",
       " 11.667: {0: {'yaw': -0.246, 'pitch': 7.526, 'roll': 104.28}},\n",
       " 11.833: {0: {'yaw': 5.92, 'pitch': 5.605, 'roll': 109.265}},\n",
       " 12.0: {0: {'yaw': 8.649, 'pitch': 4.039, 'roll': 111.918}},\n",
       " 12.167: {0: {'yaw': 6.613, 'pitch': 3.692, 'roll': 112.33}},\n",
       " 12.333: {0: {'yaw': 5.034, 'pitch': 4.668, 'roll': 111.217}},\n",
       " 12.5: {0: {'yaw': 10.109, 'pitch': 5.104, 'roll': 105.274}},\n",
       " 12.667: {0: {'yaw': 5.799, 'pitch': 4.521, 'roll': 99.774}},\n",
       " 12.833: {0: {'yaw': -9.062, 'pitch': 2.936, 'roll': 93.534}},\n",
       " 13.0: {0: {'yaw': -24.547, 'pitch': 2.836, 'roll': 89.228}},\n",
       " 13.167: {0: {'yaw': -31.568, 'pitch': 4.07, 'roll': 85.772}},\n",
       " 13.333: {0: {'yaw': -27.891, 'pitch': 2.905, 'roll': 84.693}},\n",
       " 13.5: {0: {'yaw': -46.891, 'pitch': 2.54, 'roll': 81.836}},\n",
       " 13.667: {0: {'yaw': -53.826, 'pitch': 6.366, 'roll': 76.435}},\n",
       " 13.833: {0: {'yaw': -29.334, 'pitch': 4.271, 'roll': 70.955}},\n",
       " 14.0: {0: {'yaw': -17.052, 'pitch': 3.273, 'roll': 65.76}},\n",
       " 14.167: {0: {'yaw': -11.873, 'pitch': 1.93, 'roll': 63.634}},\n",
       " 14.333: {0: {'yaw': -13.033, 'pitch': 0.507, 'roll': 62.977}},\n",
       " 14.5: {0: {'yaw': -10.977, 'pitch': 1.065, 'roll': 63.984}},\n",
       " 14.667: {0: {'yaw': -13.571, 'pitch': 3.774, 'roll': 68.507}},\n",
       " 14.833: {0: {'yaw': -17.342, 'pitch': 5.775, 'roll': 77.343}},\n",
       " 15.0: {0: {'yaw': -16.596, 'pitch': 4.993, 'roll': 83.772}},\n",
       " 15.167: {0: {'yaw': -3.883, 'pitch': 5.144, 'roll': 87.776}},\n",
       " 15.333: {0: {'yaw': 4.063, 'pitch': 2.982, 'roll': 89.982}},\n",
       " 15.5: {0: {'yaw': -0.128, 'pitch': 3.156, 'roll': 89.62}}}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
