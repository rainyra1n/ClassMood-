{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96412c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from scipy.spatial.transform import Rotation as R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a54679f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeadPose:\n",
    "    def __init__(self):\n",
    "        self.bb_detection = YOLO(r'C:\\Users\\Stepan\\Documents\\ClassMood\\yunet_headpose\\yolov8n-face-lindevs.pt')\n",
    "        self.face_mesh = mp.solutions.face_mesh.FaceMesh(\n",
    "            static_image_mode=True,\n",
    "            max_num_faces=1,\n",
    "            refine_landmarks=True,\n",
    "            min_detection_confidence=0.3,\n",
    "            min_tracking_confidence=0.5\n",
    "        )\n",
    "\n",
    "    def calibrate_matrix(self, chb_size, images=None, video=None):\n",
    "        chessboard_size = (chb_size[0] - 1, chb_size[1] - 1)\n",
    "        objp = np.zeros((chessboard_size[0] * chessboard_size[1], 3), dtype=np.float32)\n",
    "        objp[:, :2] = np.mgrid[0:chessboard_size[0], 0:chessboard_size[1]].T.reshape(-1, 2)\n",
    "        objpoints, imgpoints = [], []\n",
    "        calibration_data = []\n",
    "\n",
    "        if images:\n",
    "            if len(images) < 10:\n",
    "                raise Exception('Пожалуйста, введите не менее 10 фотографий')\n",
    "            calibration_data = images\n",
    "            calibration_mode = 'img'\n",
    "        else:\n",
    "            cap = cv2.VideoCapture(video)\n",
    "            if (cap.get(cv2.CAP_PROP_FRAME_COUNT) / cap.get(cv2.CAP_PROP_FPS)) < 2:\n",
    "                raise Exception('Пожалуйста, введите видео длинной более двух секунд')\n",
    "            \n",
    "            frame_skip = cap.get(cv2.CAP_PROP_FRAME_COUNT) // 5\n",
    "            frame_count = 0\n",
    "\n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                if frame_count % frame_skip == 0:\n",
    "                    calibration_data.append(frame)\n",
    "                frame_count += 1\n",
    "            calibration_mode = 'vid'\n",
    "\n",
    "        for path in calibration_data:\n",
    "            if calibration_mode == 'img':\n",
    "                img = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2GRAY)\n",
    "            else:\n",
    "                img = cv2.cvtColor(path, cv2.COLOR_BGR2GRAY)\n",
    "            found, corners = cv2.findChessboardCorners(img, chessboard_size, None)\n",
    "\n",
    "            if found:\n",
    "                objpoints.append(objp)\n",
    "\n",
    "                corners_refined = cv2.cornerSubPix(img, corners, (11, 11), (-1, -1), (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001))\n",
    "                imgpoints.append(corners_refined)\n",
    "        h, w = img.shape[:2]\n",
    "\n",
    "        ret, camera_matrix, self.dist_coeffs, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, (w, h), None, None)\n",
    "        self.matrix = cv2.getOptimalNewCameraMatrix(camera_matrix, self.dist_coeffs, (w, h), 1, (w, h))[0]\n",
    "\n",
    "    def frame_headpose(self, path):\n",
    "        bb_results = self.bb_detection(path, conf=0.4)\n",
    "        try:\n",
    "            image = cv2.imread(path)\n",
    "        except:\n",
    "            image = path\n",
    "\n",
    "        if not bb_results:\n",
    "            return None\n",
    "        \n",
    "        boxes = bb_results[0].boxes.xyxy.numpy()\n",
    "        head_rotations = dict()\n",
    "\n",
    "        model_points_8 = np.array([\n",
    "            (0.000000, -3.406404, 5.979507),           # 0 — нос 1\n",
    "            (0.000000, 6.545390, 5.027311),      # 1 — подбородок 152\n",
    "            (-1.785794, -0.978284, 4.850470),     # 2 — левый глаз (внутренний) 130\n",
    "            (1.785794, -0.978284, 4.850470),      # 3 — правый глаз (внутренний) 359\n",
    "            (-7.270895, -2.890917, -2.252455),     # 4 — левый глаз (внешний) 133\n",
    "            (7.270895, -2.890917, -2.252455),      # 5 — правый глаз (внешний) 362\n",
    "            (-2.056846, -4.477671, 4.520883),      # 6 — левый угол рта 78\n",
    "            (2.056846, -4.477671, 4.520883)        # 7 — правый угол рта 308\n",
    "        ], dtype=np.float64)\n",
    "        \n",
    "        for face_id, coords in enumerate(boxes):\n",
    "            face_roi = image[int(coords[1]):int(coords[3]), int(coords[0]):int(coords[2])]\n",
    "            mesh_results = self.face_mesh.process(cv2.cvtColor(face_roi, cv2.COLOR_BGR2RGB))\n",
    "            h, w = face_roi.shape[:2]\n",
    "            landmarks_2d = np.array([(mesh_results.multi_face_landmarks[0].landmark[i].x * w, mesh_results.multi_face_landmarks[0].landmark[i].y * h) for i in (1, 152, 130, 359, 133, 362, 78, 308)], dtype=np.float64)\n",
    "            \n",
    "            success, rvec, tvec = cv2.solvePnP(\n",
    "                model_points_8,\n",
    "                landmarks_2d,\n",
    "                self.matrix,\n",
    "                self.dist_coeffs,\n",
    "                flags=cv2.SOLVEPNP_SQPNP\n",
    "            )\n",
    "\n",
    "            if success:\n",
    "                rotation_matrix = cv2.Rodrigues(rvec)[0]\n",
    "                euler_angles = R.from_matrix(rotation_matrix).as_euler('xyz', degrees=True)\n",
    "\n",
    "                head_rotations[face_id] = euler_angles.tolist()\n",
    "\n",
    "        return head_rotations\n",
    "    \n",
    "    def video_headpose(self, path):\n",
    "        cap = cv2.VideoCapture(path)\n",
    "        frame_count = 0\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        main_df = dict()\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            if frame_count % 5 == 0:\n",
    "                temp = self.frame_headpose(frame)\n",
    "                main_df[round(frame_count / fps, 3)] = {i: {'yaw': round(temp[i][0], 3), 'pitch': round(temp[i][1], 3), 'roll': round(temp[i][2], 3)} for i in temp.keys()}\n",
    "\n",
    "            frame_count += 1\n",
    "        \n",
    "        return main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "987dc69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "headpose = HeadPose()\n",
    "headpose.calibrate_matrix((8, 8), video='C:/Users/Stepan/Documents/ClassMood/yunet_headpose/videos/calib/vid1.MOV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cfba7122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Stepan\\Documents\\ClassMood\\yunet_headpose\\images\\full_face_images\\1.png: 640x544 1 face, 41.2ms\n",
      "Speed: 4.1ms preprocess, 41.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 544)\n"
     ]
    }
   ],
   "source": [
    "result = headpose.frame_headpose(path=r'C:\\Users\\Stepan\\Documents\\ClassMood\\yunet_headpose\\images\\full_face_images\\1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1cf4221c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [-97.21984893183745, -1.97108583414799, -2.2642545248036985]}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "90caee65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 1 face, 31.8ms\n",
      "Speed: 1.8ms preprocess, 31.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 26.8ms\n",
      "Speed: 2.4ms preprocess, 26.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 29.3ms\n",
      "Speed: 1.3ms preprocess, 29.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 27.6ms\n",
      "Speed: 2.7ms preprocess, 27.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 27.2ms\n",
      "Speed: 1.3ms preprocess, 27.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 26.5ms\n",
      "Speed: 1.6ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 26.1ms\n",
      "Speed: 1.1ms preprocess, 26.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 26.3ms\n",
      "Speed: 1.0ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 25.5ms\n",
      "Speed: 1.0ms preprocess, 25.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 24.2ms\n",
      "Speed: 1.4ms preprocess, 24.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 24.5ms\n",
      "Speed: 1.3ms preprocess, 24.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 22.6ms\n",
      "Speed: 1.8ms preprocess, 22.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 21.1ms\n",
      "Speed: 1.4ms preprocess, 21.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 26.0ms\n",
      "Speed: 1.4ms preprocess, 26.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 21.8ms\n",
      "Speed: 1.3ms preprocess, 21.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 25.1ms\n",
      "Speed: 1.3ms preprocess, 25.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 22.4ms\n",
      "Speed: 1.4ms preprocess, 22.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 22.3ms\n",
      "Speed: 1.3ms preprocess, 22.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 25.8ms\n",
      "Speed: 1.3ms preprocess, 25.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 21.6ms\n",
      "Speed: 1.2ms preprocess, 21.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 24.4ms\n",
      "Speed: 1.3ms preprocess, 24.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 21.4ms\n",
      "Speed: 1.1ms preprocess, 21.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 25.8ms\n",
      "Speed: 1.4ms preprocess, 25.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 24.6ms\n",
      "Speed: 1.7ms preprocess, 24.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 22.0ms\n",
      "Speed: 1.2ms preprocess, 22.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 23.2ms\n",
      "Speed: 2.2ms preprocess, 23.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 21.0ms\n",
      "Speed: 1.4ms preprocess, 21.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 21.3ms\n",
      "Speed: 1.1ms preprocess, 21.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 21.2ms\n",
      "Speed: 1.3ms preprocess, 21.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 23.4ms\n",
      "Speed: 1.4ms preprocess, 23.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 24.5ms\n",
      "Speed: 2.1ms preprocess, 24.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 22.5ms\n",
      "Speed: 1.2ms preprocess, 22.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 23.8ms\n",
      "Speed: 2.5ms preprocess, 23.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 22.2ms\n",
      "Speed: 1.3ms preprocess, 22.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 21.7ms\n",
      "Speed: 1.3ms preprocess, 21.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 21.2ms\n",
      "Speed: 1.4ms preprocess, 21.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 22.5ms\n",
      "Speed: 1.8ms preprocess, 22.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 23.3ms\n",
      "Speed: 1.4ms preprocess, 23.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 23.8ms\n",
      "Speed: 1.3ms preprocess, 23.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 22.8ms\n",
      "Speed: 1.3ms preprocess, 22.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 22.3ms\n",
      "Speed: 1.5ms preprocess, 22.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 21.3ms\n",
      "Speed: 1.3ms preprocess, 21.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 27.3ms\n",
      "Speed: 1.4ms preprocess, 27.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 24.6ms\n",
      "Speed: 2.2ms preprocess, 24.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 24.1ms\n",
      "Speed: 1.4ms preprocess, 24.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 25.5ms\n",
      "Speed: 1.1ms preprocess, 25.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 22.8ms\n",
      "Speed: 1.6ms preprocess, 22.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 25.2ms\n",
      "Speed: 1.4ms preprocess, 25.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 26.7ms\n",
      "Speed: 1.3ms preprocess, 26.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 22.2ms\n",
      "Speed: 1.5ms preprocess, 22.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 22.0ms\n",
      "Speed: 1.1ms preprocess, 22.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 24.1ms\n",
      "Speed: 1.3ms preprocess, 24.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 26.6ms\n",
      "Speed: 1.4ms preprocess, 26.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 25.9ms\n",
      "Speed: 1.3ms preprocess, 25.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 26.7ms\n",
      "Speed: 1.1ms preprocess, 26.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 26.1ms\n",
      "Speed: 1.2ms preprocess, 26.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 26.5ms\n",
      "Speed: 1.3ms preprocess, 26.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 28.2ms\n",
      "Speed: 1.4ms preprocess, 28.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 28.7ms\n",
      "Speed: 1.7ms preprocess, 28.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 26.0ms\n",
      "Speed: 2.7ms preprocess, 26.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 27.2ms\n",
      "Speed: 2.4ms preprocess, 27.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 26.8ms\n",
      "Speed: 1.2ms preprocess, 26.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 25.4ms\n",
      "Speed: 1.4ms preprocess, 25.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 25.4ms\n",
      "Speed: 1.6ms preprocess, 25.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 26.5ms\n",
      "Speed: 1.3ms preprocess, 26.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 28.6ms\n",
      "Speed: 1.4ms preprocess, 28.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 26.0ms\n",
      "Speed: 2.3ms preprocess, 26.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 25.4ms\n",
      "Speed: 1.6ms preprocess, 25.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 22.4ms\n",
      "Speed: 2.8ms preprocess, 22.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 24.8ms\n",
      "Speed: 1.7ms preprocess, 24.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 21.9ms\n",
      "Speed: 1.6ms preprocess, 21.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 22.2ms\n",
      "Speed: 1.3ms preprocess, 22.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 24.4ms\n",
      "Speed: 1.4ms preprocess, 24.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 22.4ms\n",
      "Speed: 1.4ms preprocess, 22.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 23.4ms\n",
      "Speed: 1.3ms preprocess, 23.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 26.0ms\n",
      "Speed: 1.1ms preprocess, 26.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 25.4ms\n",
      "Speed: 2.7ms preprocess, 25.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 21.9ms\n",
      "Speed: 1.4ms preprocess, 21.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 26.3ms\n",
      "Speed: 1.5ms preprocess, 26.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 25.5ms\n",
      "Speed: 1.2ms preprocess, 25.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 23.1ms\n",
      "Speed: 1.7ms preprocess, 23.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 25.3ms\n",
      "Speed: 1.6ms preprocess, 25.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 23.3ms\n",
      "Speed: 1.4ms preprocess, 23.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 25.0ms\n",
      "Speed: 2.2ms preprocess, 25.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 24.4ms\n",
      "Speed: 1.4ms preprocess, 24.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 24.3ms\n",
      "Speed: 1.1ms preprocess, 24.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 22.9ms\n",
      "Speed: 1.4ms preprocess, 22.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 25.4ms\n",
      "Speed: 1.2ms preprocess, 25.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 24.1ms\n",
      "Speed: 1.1ms preprocess, 24.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 25.3ms\n",
      "Speed: 1.6ms preprocess, 25.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 36.3ms\n",
      "Speed: 1.7ms preprocess, 36.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 25.2ms\n",
      "Speed: 1.3ms preprocess, 25.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 21.8ms\n",
      "Speed: 1.7ms preprocess, 21.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 face, 22.5ms\n",
      "Speed: 1.9ms preprocess, 22.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    }
   ],
   "source": [
    "result1 = headpose.video_headpose(r'c:\\Users\\Stepan\\Documents\\ClassMood\\yunet_headpose\\videos\\vid2.MOV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8a0f6a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: {0: {'yaw': 95.55, 'pitch': -9.893, 'roll': -13.894}},\n",
       " 0.167: {0: {'yaw': 95.543, 'pitch': -10.007, 'roll': -14.069}},\n",
       " 0.333: {0: {'yaw': 95.801, 'pitch': -10.095, 'roll': -14.597}},\n",
       " 0.5: {0: {'yaw': 95.535, 'pitch': -10.044, 'roll': -14.077}},\n",
       " 0.667: {0: {'yaw': 95.443, 'pitch': -9.877, 'roll': -13.892}},\n",
       " 0.833: {0: {'yaw': 95.568, 'pitch': -10.053, 'roll': -14.702}},\n",
       " 1.0: {0: {'yaw': 95.576, 'pitch': -9.529, 'roll': -14.263}},\n",
       " 1.167: {0: {'yaw': 95.439, 'pitch': -8.746, 'roll': -13.54}},\n",
       " 1.333: {0: {'yaw': 95.217, 'pitch': -7.694, 'roll': -12.41}},\n",
       " 1.5: {0: {'yaw': 95.174, 'pitch': -6.441, 'roll': -11.939}},\n",
       " 1.667: {0: {'yaw': 95.228, 'pitch': -6.814, 'roll': -11.918}},\n",
       " 1.833: {0: {'yaw': 95.14, 'pitch': -6.22, 'roll': -11.006}},\n",
       " 2.0: {0: {'yaw': 95.098, 'pitch': -5.725, 'roll': -10.568}},\n",
       " 2.167: {0: {'yaw': 95.394, 'pitch': -5.409, 'roll': -10.991}},\n",
       " 2.333: {0: {'yaw': 95.386, 'pitch': -5.392, 'roll': -10.65}},\n",
       " 2.5: {0: {'yaw': 95.19, 'pitch': -5.512, 'roll': -10.15}},\n",
       " 2.667: {0: {'yaw': 95.045, 'pitch': -5.61, 'roll': -10.431}},\n",
       " 2.833: {0: {'yaw': 95.172, 'pitch': -5.7, 'roll': -11.098}},\n",
       " 3.0: {0: {'yaw': 94.934, 'pitch': -6.628, 'roll': -10.973}},\n",
       " 3.167: {0: {'yaw': 95.264, 'pitch': -7.279, 'roll': -11.402}},\n",
       " 3.333: {0: {'yaw': 95.335, 'pitch': -8.636, 'roll': -12.742}},\n",
       " 3.5: {0: {'yaw': 95.735, 'pitch': -10.959, 'roll': -14.329}},\n",
       " 3.667: {0: {'yaw': 96.17, 'pitch': -12.567, 'roll': -14.686}},\n",
       " 3.833: {0: {'yaw': 96.813, 'pitch': -13.889, 'roll': -16.559}},\n",
       " 4.0: {0: {'yaw': 97.084, 'pitch': -14.721, 'roll': -16.942}},\n",
       " 4.167: {0: {'yaw': 97.545, 'pitch': -15.623, 'roll': -18.389}},\n",
       " 4.333: {0: {'yaw': 98.4, 'pitch': -16.338, 'roll': -20.43}},\n",
       " 4.5: {0: {'yaw': 99.038, 'pitch': -16.54, 'roll': -22.444}},\n",
       " 4.667: {0: {'yaw': 99.254, 'pitch': -16.695, 'roll': -22.609}},\n",
       " 4.833: {0: {'yaw': 99.016, 'pitch': -16.122, 'roll': -21.754}},\n",
       " 5.0: {0: {'yaw': 98.255, 'pitch': -16.162, 'roll': -20.385}},\n",
       " 5.167: {0: {'yaw': 97.137, 'pitch': -13.719, 'roll': -18.123}},\n",
       " 5.333: {0: {'yaw': 96.114, 'pitch': -11.096, 'roll': -15.06}},\n",
       " 5.5: {0: {'yaw': 95.872, 'pitch': -10.04, 'roll': -14.647}},\n",
       " 5.667: {0: {'yaw': 95.782, 'pitch': -9.99, 'roll': -13.86}},\n",
       " 5.833: {0: {'yaw': 95.755, 'pitch': -10.322, 'roll': -13.997}},\n",
       " 6.0: {0: {'yaw': 95.567, 'pitch': -10.556, 'roll': -13.317}},\n",
       " 6.167: {0: {'yaw': 95.796, 'pitch': -10.567, 'roll': -14.925}},\n",
       " 6.333: {0: {'yaw': 95.87, 'pitch': -11.092, 'roll': -14.195}},\n",
       " 6.5: {0: {'yaw': 96.108, 'pitch': -10.716, 'roll': -13.101}},\n",
       " 6.667: {0: {'yaw': -70.699, 'pitch': -8.417, 'roll': -7.063}},\n",
       " 6.833: {0: {'yaw': -70.067, 'pitch': -8.465, 'roll': -6.427}},\n",
       " 7.0: {0: {'yaw': -69.3, 'pitch': -7.801, 'roll': -7.317}},\n",
       " 7.167: {0: {'yaw': -69.123, 'pitch': -7.702, 'roll': -7.034}},\n",
       " 7.333: {0: {'yaw': -69.752, 'pitch': -8.11, 'roll': -7.182}},\n",
       " 7.5: {0: {'yaw': -69.615, 'pitch': -7.738, 'roll': -7.282}},\n",
       " 7.667: {0: {'yaw': -70.677, 'pitch': -7.856, 'roll': -7.636}},\n",
       " 7.833: {0: {'yaw': 95.799, 'pitch': -10.37, 'roll': -13.613}},\n",
       " 8.0: {0: {'yaw': 95.591, 'pitch': -10.763, 'roll': -14.64}},\n",
       " 8.167: {0: {'yaw': 96.1, 'pitch': -10.692, 'roll': -16.309}},\n",
       " 8.333: {0: {'yaw': 96.561, 'pitch': -10.341, 'roll': -15.417}},\n",
       " 8.5: {0: {'yaw': 96.82, 'pitch': -10.123, 'roll': -14.852}},\n",
       " 8.667: {0: {'yaw': 98.116, 'pitch': -9.631, 'roll': -14.084}},\n",
       " 8.833: {0: {'yaw': 99.871, 'pitch': -8.756, 'roll': -12.51}},\n",
       " 9.0: {0: {'yaw': 102.049, 'pitch': -8.269, 'roll': -11.283}},\n",
       " 9.167: {0: {'yaw': 103.223, 'pitch': -8.554, 'roll': -10.551}},\n",
       " 9.333: {0: {'yaw': 103.843, 'pitch': -8.855, 'roll': -10.529}},\n",
       " 9.5: {0: {'yaw': 103.494, 'pitch': -8.867, 'roll': -9.596}},\n",
       " 9.667: {0: {'yaw': 103.385, 'pitch': -8.581, 'roll': -10.535}},\n",
       " 9.833: {0: {'yaw': 103.004, 'pitch': -8.591, 'roll': -10.628}},\n",
       " 10.0: {0: {'yaw': 101.882, 'pitch': -8.713, 'roll': -10.645}},\n",
       " 10.167: {0: {'yaw': 100.099, 'pitch': -9.18, 'roll': -12.46}},\n",
       " 10.333: {0: {'yaw': 97.818, 'pitch': -9.426, 'roll': -13.046}},\n",
       " 10.5: {0: {'yaw': 96.342, 'pitch': -9.893, 'roll': -13.679}},\n",
       " 10.667: {0: {'yaw': 95.39, 'pitch': -10.41, 'roll': -14.634}},\n",
       " 10.833: {0: {'yaw': 95.239, 'pitch': -10.167, 'roll': -14.263}},\n",
       " 11.0: {0: {'yaw': 95.317, 'pitch': -9.917, 'roll': -14.117}},\n",
       " 11.167: {0: {'yaw': 95.553, 'pitch': -8.778, 'roll': -16.1}},\n",
       " 11.333: {0: {'yaw': 95.511, 'pitch': -6.669, 'roll': -18.87}},\n",
       " 11.5: {0: {'yaw': 95.407, 'pitch': -3.836, 'roll': -21.092}},\n",
       " 11.667: {0: {'yaw': 95.08, 'pitch': -1.72, 'roll': -22.96}},\n",
       " 11.833: {0: {'yaw': 95.012, 'pitch': 0.514, 'roll': -24.212}},\n",
       " 12.0: {0: {'yaw': 94.737, 'pitch': 1.855, 'roll': -24.662}},\n",
       " 12.167: {0: {'yaw': 94.754, 'pitch': 2.205, 'roll': -24.657}},\n",
       " 12.333: {0: {'yaw': 94.708, 'pitch': 1.699, 'roll': -24.279}},\n",
       " 12.5: {0: {'yaw': 94.949, 'pitch': -0.626, 'roll': -22.662}},\n",
       " 12.667: {0: {'yaw': 95.238, 'pitch': -3.754, 'roll': -20.723}},\n",
       " 12.833: {0: {'yaw': 95.434, 'pitch': -7.459, 'roll': -17.677}},\n",
       " 13.0: {0: {'yaw': 95.53, 'pitch': -9.999, 'roll': -15.7}},\n",
       " 13.167: {0: {'yaw': 95.66, 'pitch': -11.782, 'roll': -13.422}},\n",
       " 13.333: {0: {'yaw': 95.425, 'pitch': -12.063, 'roll': -11.909}},\n",
       " 13.5: {0: {'yaw': 95.326, 'pitch': -13.4, 'roll': -10.262}},\n",
       " 13.667: {0: {'yaw': 94.945, 'pitch': -16.196, 'roll': -6.574}},\n",
       " 13.833: {0: {'yaw': 93.699, 'pitch': -17.254, 'roll': 0.019}},\n",
       " 14.0: {0: {'yaw': 93.509, 'pitch': -18.028, 'roll': 3.848}},\n",
       " 14.167: {0: {'yaw': 92.74, 'pitch': -18.377, 'roll': 6.956}},\n",
       " 14.333: {0: {'yaw': 92.949, 'pitch': -18.586, 'roll': 6.335}},\n",
       " 14.5: {0: {'yaw': 92.934, 'pitch': -18.361, 'roll': 6.049}},\n",
       " 14.667: {0: {'yaw': 93.88, 'pitch': -16.98, 'roll': 1.232}},\n",
       " 14.833: {0: {'yaw': 94.628, 'pitch': -14.491, 'roll': -5.203}},\n",
       " 15.0: {0: {'yaw': 95.231, 'pitch': -12.422, 'roll': -10.492}},\n",
       " 15.167: {0: {'yaw': 95.812, 'pitch': -10.153, 'roll': -13.676}},\n",
       " 15.333: {0: {'yaw': 95.896, 'pitch': -9.166, 'roll': -15.65}},\n",
       " 15.5: {0: {'yaw': 95.992, 'pitch': -9.04, 'roll': -15.572}}}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c094073a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [130, 359, 133, 362, 1, 78, 308, 152]:\n",
    "                cv2.circle(face_roi, (int(mesh_results.multi_face_landmarks[0].landmark[i].x * w), int(mesh_results.multi_face_landmarks[0].landmark[i].y * h)), 1, (0, 255, 255), -1)\n",
    "                print(int(mesh_results.multi_face_landmarks[0].landmark[i].x * w), int(mesh_results.multi_face_landmarks[0].landmark[i].y * h))\n",
    "            cv2.imwrite(f'C:/Users/Stepan/Documents/ClassMood/yunet_headpose/images/images_with_landmarks/face{face_num}.png', face_roi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
